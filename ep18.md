http://bananasandlenses.net/episode018

РЧ: Доброго времени суток, вы слушаете 18 выпуск подкаста бананы и линзы. С вами сегодя Денис Редозубов

ДР: Привет

РЧ: Денис Шевченко

ДШ: Приветствую

РЧ: и я, Роман Чепляка. Первая тема у нас сегодня посвящена расширению Strict, которое мы обсуждали в предыдущих выпусках. Это расширение, которое позволяет анотировать модуль и код в этом модуле будет компилироваться как строгий код. Это, по крайней мере, идея. Были спекуляции на тему того, что это расширение сделает Хаскель более простым для новичков, которым не хочется разбираться в тонкостях ленивых вычислений. Однако, как выяснилось, чтобы разбираться, что же делает эта прагма Strict, даже не все авторы компилятора это понимают. И вот, на этой неделе, было письмо в рассылку ghc-devs от Омера Синана Агасана, как-то так, который интересуется, а почему ... Значит, он написал функцию zip, которая деконструирует списочные аргументы на head и tail и вот эти head и tail, несмотря на то, что модуль анотирован, как Strict, они строго не вычисляются. То есть `zip (h:hs) (y:ys)` и вот эти `x` и `y` продолжают быть санками(thunk). Он спрашивает: "как же так и почему?". И получилась довольно интересная дискуссия, в которой было несколько версий, как же всё-таки должен работать Strict. То есть в первом приближении всё понятно и все были согласны, что Strict должен всё форсировать, но когда стали углубляться в детали, стало понятно, что ничего не понятно. Я предложил своё видение этого, которое в чём-то основано на другом, похожем расширении - это [UnliftedDataTypes](https://ghc.haskell.org/trac/ghc/wiki/UnliftedDataTypes). Я напомню, UnliftedDataTypes делает некоторые типы unlifted и это означает, что все байндинги этого типа автоматически вычисляются. То есть мы работаем в терминах именно байндингов, в терминах переменных, и мне казалось эта концепция хорошо переносится сюда. Вот я предложил ... Тут что важно, важно, может быть, даже не то, какая именно будет семантика, важно чтобы она была простой. Чтобы можно было любому человеку объяснить в двух словах что делает прагма Strict. И моя попытка объяснить была именно такой, что если у нас есть модуль Strict, то все переменные, которые там определены, будут автоматически вычислены. Ну и, наверное, стоило бы добавить, что и function applications тоже будут автоматически вычислены. Хотя, может быть, это и следует. Да, главная идея такая, что любое определение будет строго вычислено. С другой стороны, Саймон Пейтон Джонс предложил своё определение. Определение Саймона тоже на первый взгляд простое и понятное. Саймон говорит, что код, который скомпилирован со Strict, не будет создавать санков. То есть он определяет это не в терминах такой денотационной семантики и не в терминах синтаксических, а в терминах операционных. Код, как он будет работать? Он будет работать каким-то таким образом, чтобы не создавать санков. Но там есть проблема с определением Саймона. Я, по крайней мере, 2 проблемы нашёл и Саймон со мной согласился и нашёл ещё третью проблему в собственном определении.
Во-первых, что будет, если у нас какой-то байндинг не используется? Тут ещё надо сказать, вот мы использовали аналогию с UnliftedDataTypes, ещё есть аналогия с [Bang Patterns](https://downloads.haskell.org/~ghc/7.8.4/docs/html/users_guide/bang-patterns.html). То есть интуитивно в модуле Strict у нас все patterns с восклицательными знаками. И что будет, если мы, например, скажем, что `let _ = чему-то-undefined in что-то`. Вот будет это `undefined` вычислено или нет? По аналогии с `bang patterns` он будет вычислен даже несмотря на то, что он не используется. Но, по определению Саймона, полностью легально его просто выкинуть и не вычислять, потому что коль скоро мы не создаём санков, то всё хорошо. Но понятно, что это не очень согласуется с идеей строгого вычисления всего и, естественно, семантика у этих двух вычислений очень разная, потому что в одном случае мы получаем исключение, в другом случае мы исключения не получаем.
Другой пример, который я привёл, это `f g = g undefined`. То есть мы вызываем какую-то функцию с аргументом `undefined`. По логике, коль скоро наш модуль Strict, то эта аппликация должна быть строгой, то есть должно получиться исключение. Даже если `g` это какой-нибудь `const`, который аргумент свой не вычисляет, но коль скором мы в строгом модуле передаём в функцию `undefined`, то должно получиться исключение. Правда же. То есть это применение должно быть строгим. Но, поскольку `undefined` это не санк, это некий CAF([constant applicative form](https://wiki.haskell.org/Constant_applicative_form)), который определён... Вернее, это санк, но он определён в другом модуле. То есть, может быть, изначально он что-то типа санка, но потом он заменён исключением и каждый раз, когда мы обращаемся к `undefined` мы получаем то самое исключение. Как-то так. Ну суть важно. Главное, что `undefined` для наших целей - это указатель. То есть это на санк, который мы создаём, идея Саймона была в том, что мы не создаём новых санков, но это уже CAF, который уже создан. Мы же его не создаём, мы его просто передаём и поэтому тоже легально его не вычислять в этом контексте. Потом Саймон сам задаётся вопросом - а действительно, что же будет, например, если мы просто вызываем что-то типа `f (g x)`, где `f` определена в ленивом модуле? То есть будет ли эта аппликация ленивой или строгой? То есть с одной стороны она должна быть ленивой, поскольку `f` определена в ленивом модуле, с другой стороны, она должна быть строгой, потому что `f (g x)` определена в строгом модуле. В общем ничего не понятно с этой прагмой.

ДШ: Сами себе проблемы сделали, теперь гадают, как же мы это разрулим.

РЧ: Да, да. Типа того. Вот авторы этой прагмы, это Йохан Тибль и Адам Сендберг Эриксон. И я так понимаю, что это был Google Summer of Code проект Адама и вот они тоже, как бы, над этим думают. Йохан отписался, что у него мало времени, чтобы над всем этим думать. И сейчас, поскольку это уже должно войти в GHC 8.0, который вот-вот, совсем скоро, должен быть выпущен, то консенсут такой, что давайте мы попробуем задокументировать как-то что же мы тут наделали и как оно должно себя вести, а дальше будем думать.

ДР: У меня не до конца срастается ещё, как эта прагма должна работать с какими-нибудь бесконечными структурами, например?

РЧ: Ну, там проще, потому что мы только говорим, что это Weak Head Normal Form. То есть оно не полностью вычисляется, оно вычисляется только до WHNF. Вопрос в том, что именно будет вычисляться до WHNF? Потому что, если, например, у нас есть сложные вложенные patterns, то будет ли только верхний уровень вычислен до WHNF или будут все отдельные переменные вычислены до WHNF? 

08:25
